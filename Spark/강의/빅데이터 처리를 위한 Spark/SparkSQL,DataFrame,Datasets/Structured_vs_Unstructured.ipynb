{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/02 16:28:11 WARN Utils: Your hostname, MZC01-HYUCKSANGCHO.local resolves to a loopback address: 127.0.0.1; using 10.90.8.26 instead (on interface en0)\n",
      "24/04/02 16:28:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/02 16:28:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster('local').setAppName('structured-unstructured')\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예를 들어 다음과 같이 데이터가 주어질 때 미국의 $2,000불 이상 가져오기 위한 방법은??\n",
    "ticker = sc.parallelize([\n",
    "    (1, (\"Google\", \"USA\")),\n",
    "    (2, (\"Netflix\", \"USA\")),\n",
    "    (3, (\"Amazon\", \"USA\")),\n",
    "    (4, (\"Samsung\", \"Korea\")),\n",
    "    (5, (\"Kakao\", \"Korea\"))\n",
    "])\n",
    "\n",
    "prices = sc.parallelize([\n",
    "    (1, (2984, \"USD\")),\n",
    "    (2, (645, \"USD\")),\n",
    "    (3, (2984, \"USD\")),\n",
    "    (4, (11234, \"KRW\")),\n",
    "    (5, (1234512, \"KRW\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (('Google', 'USA'), (2984, 'USD'))),\n",
       " (3, (('Amazon', 'USA'), (2984, 'USD')))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법 1 : Join -> Filter\n",
    "tickerPrice = ticker.join(prices)\n",
    "tickerPrice.filter(lambda x : x[1][0][1] == \"USA\" and x[1][1][0] > 2000).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (('Google', 'USA'), (2984, 'USD'))),\n",
       " (3, (('Amazon', 'USA'), (2984, 'USD')))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법 2 : Filter -> Join\n",
    "filterticker = ticker.filter(lambda x : x[1][1] == \"USA\")\n",
    "filterprices = prices.filter(lambda x : x[1][0] > 2000)\n",
    "filterticker.join(filterprices).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방법1과 방법2 중에 뭐가 더 효율 적일까?\n",
    "- 방법2 셔플링을 최소화했기 때문에\n",
    "- 매번 최적화 작업이 필요한가? 스파크가 알아서 해주면 좋겠음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 구조\n",
    "- Unstructured\n",
    "    - 로그 파일\n",
    "    - 이미지 \n",
    "    - 동영상\n",
    "\n",
    "- Semi Structured: 행과 열이 존재\n",
    "    - CSV\n",
    "    - JSON\n",
    "    - XML\n",
    "\n",
    "- Structured: 행과 열 + 스키마 존재\n",
    "    - 데이터베이스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RDD\n",
    "    - 데이터의 구조를 모르기때문에 개발자 의존\n",
    "    - 개발자마다 성능이 천차만별\n",
    "- Structured Data\n",
    "    - 어떤 테스크를 수행할 것 인지 정의만하면 자동으로 최적화\n",
    "    - SparkSQL은 구조화 된 데이터를 다룰 수 있게 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
