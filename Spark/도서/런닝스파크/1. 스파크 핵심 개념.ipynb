{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 스파크 컴포넌트 구성요소\n",
    "- 스파크는 여러 특수한 목적에 맞게 설계된 다양한 컴포넌트로 구성되어 있다.\n",
    "1. 스파크 코어\n",
    "    - 작업 스케줄링, 메모리 관리, 장애 복구, 저장장치 연동 등 기능 들로 구성\n",
    "    - RDD를 정의하는 API의 기반\n",
    "2. 스파크 SQL\n",
    "    - 정형 데이터 처리를 위한 패키지\n",
    "    - SQL을 사용해 대규모 분산 정형 데이터 처리를 위한 모듈\n",
    "3. 스파크 스트리밍\n",
    "    - 실시간 스트리밍 데이터 처리하는 프레임워크\n",
    "4. 스파크 GraphX\n",
    "    - 그래프(ex. SNS 친구 관계 그래프)를 다루기 위한 라이브러리\n",
    "5. 스파크 MLlib\n",
    "    - 머신 러닝 알고리즘 라이브러\n",
    "6. 클러스터 매니저\n",
    "    - 스파크의 노드를 관리하기 위한 매니저\n",
    "    - 얀(YARN), 아파치 메소스(Mesos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스파크 분산 실행을 위한 컴포넌트\n",
    "- 드라이버 프로그램 <-> 작업 노드(익스큐터)\n",
    "- 스파크 애플리케이션은 드라이버 프로그램으로 구성된다.\n",
    "- 드라이버 프로그램은 내가 Spark 코드를 작성한 main함수를 갖고 있으면 클러스터의 분산 데이터세트를를 정의하고 연산작업을 익스큐터라 불리는 작업자 노드에 전달한다.\n",
    "- 드라이버 프로그램은 SparkContext 객체를 통해 스파크에 접속한다.\n",
    "- 즉, 드라이버 프로그램이 실행 노드에 작업은 분배한다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
