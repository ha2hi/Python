### Producer(프로듀서)
- producer는 key_serializer와 value_serializer을 통해 직렬화함.
- Producer 객체를 close하기 전 flush하는 이유
  - 프로듀서는 브로커에 메시지를 전달 하기 전 버퍼에 저장 후 배치로 전송
  - 이 때 flush를 하지 않고 close를 하면 버퍼에 저장된 데이터가 전송이 되지 않기 때문에 유실 가능성이 있다.
  - 버퍼에 저장하는 시간은 batch_size, 크기는 linger_ms를 통해 설정
- 파티션 전략
  - 키기반 파티셔닝
    - 동일한 키는 동일한 파티션으로 이동(순서 보장 가능)
    - murmur2 해시 전략
    - 특정 파티션에 데이터가 몰릴 수 있음
  - 라운드로빈 파티션
    - 레코드를 전송할 때 마다 다른 파티션에 보내기 때문에 균등 분배
    - 스티키파티션에 비해 비효율적
  - 스티키파티션(default)
    - 레코드를 배치 단위로 한 번에 파티션에 보내기 때문에 효율적
    - 라운드로빈은 레코드 단위로 파티션이 분배되는 반면 스티키 방식은 레코드를 1개의 배치로 묶어 하나의 파티션으로 전송
  - kakfa-python 라이브러리에서 `partitioner` 옵션으로 지정 가능
- 고가용성(HA)
  - acks를 통해 브로커의 응답을 통해 정상적으로 쓰기가 되었는지 확인할 수 있음
  - min.insync.replicas를 통해 ISR의 응답 수를 지정할 수 있음
    - 예를 들어 replicas가 3이고, min.insync.replicas가 1인 경우 리더 파티션만 응답하고 2인 경우 리더 브로커와 최소 1개 이상의 replicas 브로커가 문제 없는 경우 응답
  - retries와 retry.backoff.ms를 통해 쓰기에서 문제가 생기는 경우 재시도를 할 수 있음
    - 만약 해당 설정을 안하면 데이터 유실이 발생할 수 있기 때문
    - retries는 재시도 횟수
    - retry.backoff.ms는 몇초 후 재시도할지에 대한 시간(default : 100ms)
  - delivery.timeout.ms를 통해 성공 혹은 실패 시 허용되는 최대 시간
    - 메시지 전송전 대기 시간 + 브로커 승인 완료(acks) 시간 + 재시도 가능한 전송 실패에 대한 총 시간임
    - default는 120000밀리초(2분)
   
- 멱등성(Idempotent)
  - enable.idempotence를 True로 설정하여 네트워크 재시도로 인해 중복데이터가 저장 되지않도롣 해야됨.
    - Kafka 3.0 이상 버전에서는 Default로 True로 설정됨.
  - max.in.flight.requests.per.connection 설정(default: 5)
    - 해당 설정은 프로듀서가 브로커와의 단일 연결에서 응답을 기다리지 않고 동시에 전송할 수 있는 최대 요청 수
- 배치(Batch)
  - 프로듀서에서 압축을 통해 데이터를 전송하는 경우 디스크 공간 절약과 전송 속도가 빠름.
  - compression_type(default: None)
    - 압축을 타입을 지정할 수 있음
    - gzip, snappy, lz4, zstd 중 선택 가능
      - 일반적으로 snaapy를 주로 사용
      - snappy : 매우 빠른 압축/압축 해제 속도, 낮은 CPU 사용량, 상대적으로 압축률이 낮음
      - gzip : 매우 높은 압축률, 늦은 압축/압축 해제 속도, 높은 CPU 사용량
      - lz4 : 가장 빠른 압축/압축 해제 속도, 가장 낮은 압축률
  - linger.ms(default: 0)
    - 프로듀서가 카프카에 데이터를 전송하기 전에, 버퍼에 저장할 최대 시간
    - 0인경우 데이터가 도착하는 즉시 브로커에 데이터 전송
  - batch.size(default: 16KB)
    - batch.size가 도달할 때 까지 버퍼에 데이터를 저장
    - 만약 버퍼 크기가 batch.size에 도달한 경우 linger.ms의 설정과 관계 없이 바로 데이터 전송
  - 압축은 컨슈머에서 해제해야 됨.
  
### Consumer(컨슈머)
- Consumer는 key_deserializr와 value_desrializer를 통해 역직렬화 함.
- auto.offset.reset을 통해 메시지를 어디서 부터 읽을지 설정 가능
  - none : 커밋된 offset 정보가 없을 때 예외를 발생
  - earliest : 가장 처음(offset 0)부터 읽음
  - latest : 이후 생성되는 메시지부터 읽음, 이전 메시지 읽지 않음
- Consumer는 Poll을 통해 레코드를 가져오고, 레코드 처리가 완료되면 commit함.  
- Shutdown Hook을 통해 애플리케이션 종료 시 graceful하게 종료되도록 설정하는 것이 좋음
  - 안정성, 신뢰성, 무결성을 보장하기 위해 구현 필요
- 파티션 리밸런싱
  - 컨슈머 그룹 내의 컨슈머 추가 및 삭제 시 혹은 파티션 추가 및 삭제가 되는 경우 파티션 리밸런싱 과정이 이뤄짐
  - Eager Rebalance : 모든 읽기 작업이 중단되고, 리밸런싱 이후 읽기 작업이 재개
    - RangeAssignor :연속적인 범위로 파티션을 할당
    - RoundRobinAssignor : 라운드로빈(균등하게)방식으로 파티션을 할당
    - StickyAssignor : 기존 컨슈머가 담당하는 파티션은 최대한 유지한채로 균등하게 파티션 할당
  - Cooperative Rebalance : 읽기 과정을 유지한채로 리밸런싱이 이뤄짐
    - Cooperative StickyAssignor : 파티션 이동을 최소화하며, 컨슈머가 리밸런싱 중에도 읽기 가능
- 브로커가 session.timeout.ms 시간 동안 하트비트를 전달 받지 못한 경우 리밸런싱 발생
- auto.coomit.interval.ms은 offset commit 발생 주기
- heartbeat.interval.ms
  - 컨슈머가 브로커에게 컨슈머 사용 중임을 알림
  - default 3초
  - 보통 session.timeout.ms의 1/3으로 설정
- session.timeout.ms
  - default 45초
  - hearbeat 메시지가 session.timeout.ms 시간 내로 브로커에 전달하지 않는 경우 컨슈머를 사용하지 않는 것으로 간주
- max.poll.interval.ms
  - poll() 메서드를 호출 후 다음 poll() 작업 전까지 허용되는 최대 시간
  - 따라서 메시지를 가져와 처리하는데 걸리는 최대 시간
  - default 5분
  - 처리 시간
- max.poll.records
  - default 500
  - poll() 요청 당 한 번에 가져올 레코드 개수
  - 메시지가 작은 경우 늘리고, 메시지가 큰 경우 줄여야함
- fetch.min.bytes
  - default 1 Bytes
  - poll() 요청을 보냈을 때, 브로커가 응답을 보내기 전에 최소한 이만큼의 바이트(bytes)를 사용할 수 있을 때까지 기다림
- fetch.max.wait.ms
  - default 500ms(0.5초)
  - fetch.min.bytes 조건을 만족하기 위해 브로커가 컨슈머 요청에 대해 응답을 지연시킬 수 있는 최대 시간을 정의
- max.partition.fetch.bytes
  - poll() 한 번 호출 시, 단일 파티션에서 가져올 수 있는 최대 데이터의 양을 정의합니다.
  - default 1MB
- fetch.max.bytes
  - default 50MB
  - poll() 한 번 호출 시, 브로커로부터 모든 구독된 파티션(또는 할당된 파티션)에 걸쳐 가져올 수 있는 최대 데이터의 총량

### Broker(브로커)
- offset.retention.minutes는 커밋된 오프셋 정보를 얼마나 오랫동안 유지할지 결정
  - 만약 컨슈머 그룹이 비활성인 상태에서 offsets.retention.minutes=4320(3분)으로 설정 후 4일이 지난 경우 마지막 commit지점 찾을 수 없음
  - 컨슈머 그룹이 계속 활성 중인 상태인경우 해당 설정 값은 중요하지 않음.
  - default는 7일